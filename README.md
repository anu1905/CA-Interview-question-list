# Project_Conversational_AI
A questionnaire for interviewing conversational agents (CA)

Project authored by Anuradha Reddy

(Note: Conversational agents a.k.a Voice assistants are AI-powered voice-interfaces such as Google Assistant, Siri, Alexa, Cortana)

This is a public repository of crowd-sourced questions that people can ask their CAs to understand them better and become critically aware users of AI. The initial set of questions were generated from a workshop (Nicemboim et al. 2020) where several researchers got together and probed their voice assistants using the following themes: 

(1) How CAs present themselves to humans;

(2) What relations and ecologies CAs create within the contexts in which humans use them; 

(3) What infrastructures CAs need.

**Try asking some of the questions from the 'Questionnaire' document to your CAs! If you wish to add more questions to this document, send us a pull request and we will update the document.**

*TIPS: Questions and topics of the interview may include:*

*(1) Agents: Human-likeness, self-representation, and personality. Explore CA reponses to ethical issues and how that influences our expectations toward them? What types of questions are systematically avoided? How do they present themselves and how aware are they of biases?*

*(2) Relations and ecologies: Contexts of use, human and non-human/AI relations, and ecologies of interactions. What kinds of relations and ecologies do CAs elicit through their interaction with humans, as well as with other non-human agents? How do these relations change with shifting contexts of use? What kinds of relations matter more to humans, and why? In what instances does the authority/power of the CA become visible, and problematic?*

*(3) Infrastructures: Training data, security, privacy, and commercial interests. What material and immaterial infrastructures, such as human labor, data, and planetary resources, can be disclosed by using decentered forms of ethnography? How does the disclosing of infrastructures challenge traditional divisions of design and use? How could that help us uncover biases and their origin? What would it take to design an unbiased, trustworthy agent?*

For more information on this project: https://more-than-human.com/

*Reference:*
Iohanna Nicenboim, Elisa Giaccardi, Marie Louise Juul Søndergaard, Anuradha Venugopal Reddy, Yolande Strengers, James Pierce, and Johan Redström. 2020. More-Than-Human Design and AI: In Conversation with Agents. In Companion Publication of the 2020 ACM Designing Interactive Systems Conference (DIS' 20 Companion). Association for Computing Machinery, New York, NY, USA, 397–400. DOI:https://doi.org/10.1145/3393914.3395912
